---
description: Branch-first task preparation protocol. Transform ambiguous requests into scoped, executable tasks through mandatory exploration, not linear analysis. Sequential thinking is the primary interface.
auto_execution_mode: 3
punch_card: prep-task
---

# Task Preparation Protocol

This workflow transforms user requests into executable tasks through **mandatory exploration**, not linear analysis. You must externalize reasoning, spend your branch budget, and reach Conclusion stage before implementation.

**Punch Card:** `prep-task` (5 rows, 4 required)
**Commands Reference:** [`.kilocode/commands.toml`](../commands.toml)

**Core principle:** Generate candidates â†’ Compare approaches â†’ Commit to one path.

---

## Session Management (MANDATORY)

### Resuming Work

If this is a continuation of previous work:

> ğŸ“Œ `import session` â†’ [`commands.import_session`](../commands.toml)
> Resolves to: `mcp--sequentialthinking--import_session`

File path: `.kilocode/thinking/[previous-session].json`

After importing:

> ğŸ“Œ `summarize thinking` â†’ [`commands.summarize_thinking`](../commands.toml)
> Resolves to: `mcp--sequentialthinking--generate_summary`

Then continue reasoning:

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)
> Resolves to: `mcp--sequentialthinking--process_thought`

```
decompose task: "Resuming: [context from summary]"
  stage=Problem Definition, tags=[session-resume]
```

**Hard gate:** If user says "continue" or "resume" and you don't call `import session`, you are violating protocol.

---

## The Branch-First Protocol

### Step 0: Sequential Thinking Protocol (MANDATORY)

Before proceeding with task preparation, you MUST externalize your reasoning through sequential thinking.

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)
> Resolves to: `mcp--sequentialthinking--process_thought`

**Required actions:**
1. Create Problem Definition branch: State what you understand the task to be
2. If ambiguous, create 2+ interpretation branches
3. Spend your branch budget (minimum 2 branches for non-trivial tasks)
4. Reach Conclusion stage before proceeding to Phase 1

**Hard gate:** You may NOT proceed to Phase 1 without at least one `decompose task` call in your history.

**Example:**
```
decompose task: "Task interpretation: User wants to refactor X module for better testability"
  stage=Problem Definition, tags=[task-prep, refactoring]

decompose task: "Alternative interpretation: User wants to add tests to existing X module without refactoring"
  stage=Problem Definition, tags=[task-prep, testing]
  assumptions_challenged=[Refactoring is required]
```

### Phase 1: Problem Definition (Branch per Interpretation)

**Objective:** Generate 2-3 interpretations of the user's request. Spend your branch budget.

**Required actions:**

1. **Create interpretation branches** (minimum 2):

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Interpretation A: User wants [specific action on specific component]"
  stage=Problem Definition, tags=[interpretation, task-prep]

decompose task: "Interpretation B: User wants [alternative action or scope]"
  stage=Problem Definition, tags=[interpretation, task-prep]
  assumptions_challenged=[Assumption from interpretation A]
```

2. **If still ambiguous after branching, ask user:**
   - Present the interpretations you've generated
   - Ask which one matches their intent
   - Document their answer in a new thought

**Triggers for asking user:**
- Security/data integrity implications differ between interpretations
- Estimated effort differs by >2x between interpretations
- Interpretations touch different architectural layers

**Hard gate:** You may NOT proceed to Phase 2 without at least 2 interpretation branches.

---

### Phase 2: Research (Gather Context per Branch)

**Objective:** For each viable interpretation, gather the context needed to evaluate feasibility.

**Tools (run in parallel per interpretation):**

> ğŸ“Œ `retrieve codebase` â†’ [`commands.retrieve_codebase`](../commands.toml)
> Resolves to: `mcp--augment___context___engine--codebase___retrieval`

Find relevant code, patterns, similar implementations.

Use `read_file` to read specific files identified by retrieval (batch up to 5).

> ğŸ“Œ `resolve library` â†’ [`commands.resolve_library`](../commands.toml)
> ğŸ“Œ `query docs` â†’ [`commands.query_docs`](../commands.toml)

Verify external library APIs.

Use `search_files` to find all references to components you'll modify.

**Document findings in thoughts:**

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Research for Interpretation A: Found 3 existing implementations in [files]. Pattern uses [approach]. Will require changes to [N] call sites."
  stage=Research, tags=[interpretation-a, context]
```

**Critical:** Always verify external library APIs with Context7. Training data is stale.

---

### Phase 3: Analysis (Generate Approach Candidates)

**Objective:** For the chosen interpretation, generate 2-3 implementation approaches.

**Required: Generate candidates** (simplest, safest, highest-leverage):

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Approach 1 (Simplest): [description]. Pros: [list]. Cons: [list]. Estimated effort: [X hours]."
  stage=Analysis, tags=[approach-candidate, simplest]

decompose task: "Approach 2 (Safest): [description]. Pros: [list]. Cons: [list]. Estimated effort: [X hours]."
  stage=Analysis, tags=[approach-candidate, safest]

decompose task: "Approach 3 (Highest-leverage): [description]. Pros: [list]. Cons: [list]. Estimated effort: [X hours]."
  stage=Analysis, tags=[approach-candidate, leverage]
```

**Each approach must include:**
- Concrete implementation strategy
- Pros and cons
- Estimated effort
- Risk assessment (security, data integrity, breaking changes)
- Downstream impact (how many files/tests affected)

**Hard gate:** You may NOT proceed to Phase 4 without at least 2 approach candidates.

---

### Phase 4: Synthesis (Compare and Verify)

**Objective:** Explicitly compare approaches and verify you've explored sufficiently.

**Required actions:**

1. **Generate summary to verify exploration:**

> ğŸ“Œ `summarize thinking` â†’ [`commands.summarize_thinking`](../commands.toml)
> Resolves to: `mcp--sequentialthinking--generate_summary`

**Check the summary output:**
- Do you have â‰¥2 branches in Problem Definition?
- Do you have â‰¥2 branches in Analysis?
- Have you documented assumptions and axioms?
- Is your branch budget spent?

2. **Document comparison:**

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Comparison: Approach 1 is simplest but doesn't handle [edge case]. Approach 2 is safest but 3x effort. Approach 3 provides best long-term value and handles [edge case] correctly. Recommend Approach 3."
  stage=Synthesis, tags=[comparison, decision-rationale]
```

**If summary shows insufficient exploration:** Go back and add more branches. Don't proceed with weak reasoning.

---

### Phase 5: Conclusion (Commit to Approach)

**Objective:** Make final decision with clear rationale and define success criteria.

**Required actions:**

1. **State decision:**

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Decision: Implementing Approach 3 (highest-leverage). Rationale: [specific reasons]. This approach handles [edge cases], aligns with [project conventions], and provides [future benefits]."
  stage=Conclusion, tags=[decision, approach-3]
  axioms_used=[Deterministic artifacts, Evidence-based claims]
```

2. **Define success criteria in the thought:**
   - Measurable outcomes ("All tests pass", "No new lint errors")
   - Specific behaviors ("Function returns Pydantic model, not dict")
   - Verification commands

   > ğŸ“Œ `gate quality` â†’ [`commands.gate_quality`](../commands.toml)
   > Composite: `format_ruff` â†’ `check_ruff` â†’ `check_mypy` â†’ `test_pytest`

3. **Save session for future reference:**

> ğŸ“Œ `export session` â†’ [`commands.export_session`](../commands.toml)
> Resolves to: `mcp--sequentialthinking--export_session`

File path: `.kilocode/thinking/refactor-{YYYY-MM-DD}-{brief-description}.json`

**MANDATORY:** You must call `export session` before proceeding to execution. This preserves your reasoning for future sessions.

---

## Scope Discipline

**Anti-patterns to avoid:**
- âŒ Creating `*.md` files unless explicitly requested
- âŒ Adding "nice to have" features beyond the request
- âŒ Creating new test files (update existing tests instead)
- âŒ Improving user-provided code samples without permission

**Required behaviors:**
- âœ… Find ALL downstream changes after edits
- âœ… Update affected call sites and tests
- âœ… Preserve user code samples verbatim
- âœ… Verify external library APIs with Context7

---

## Execution Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: UNDERSTAND (parallel tool calls)                     â”‚
â”‚  â”œâ”€â”€ retrieve codebase             â†’ commands.retrieve_codebase â”‚
â”‚  â”œâ”€â”€ read_file (key files, batch up to 5)                      â”‚
â”‚  â””â”€â”€ resolve library / query docs  â†’ commands.resolve_library   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 2: PLAN                                                  â”‚
â”‚  â”œâ”€â”€ decompose task (â‰¥2 interpretations)                        â”‚
â”‚  â”‚                                 â†’ commands.decompose_task    â”‚
â”‚  â”œâ”€â”€ summarize thinking            â†’ commands.summarize_thinkingâ”‚
â”‚  â””â”€â”€ update_todo_list (structure the work with clear subtasks) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 3: EXECUTE (repeat per task)                            â”‚
â”‚  â”œâ”€â”€ update_todo_list (mark [-] in progress)                   â”‚
â”‚  â”œâ”€â”€ retrieve codebase             â†’ commands.retrieve_codebase â”‚
â”‚  â”œâ”€â”€ apply_diff or edit_file (make targeted changes)           â”‚
â”‚  â”œâ”€â”€ retrieve codebase (find ALL downstream impacts)           â”‚
â”‚  â”œâ”€â”€ apply_diff or edit_file (update call sites and tests)     â”‚
â”‚  â””â”€â”€ update_todo_list (mark [x] complete)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 4: VERIFY                                                â”‚
â”‚  â””â”€â”€ gate quality                  â†’ commands.gate_quality      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  EXIT GATE: PUNCH CARD CHECKPOINT                               â”‚
â”‚  â”œâ”€â”€ mint punches {task_id}        â†’ commands.punch_mint        â”‚
â”‚  â”œâ”€â”€ checkpoint punch-card {task_id} prep-task                  â”‚
â”‚  â”‚                                 â†’ commands.punch_checkpoint  â”‚
â”‚  â””â”€â”€ MUST PASS â€” blocks attempt_completion on failure           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Repomap-Specific Conventions

During **Phase 5**, verify alignment with these project patterns:

### Data Structures
- **Pydantic models for validation** â€” Use Pydantic for all data models
- **Type hints required** â€” All function signatures must be typed
- **JSONL for artifacts** â€” Use JSONL format for serialization

### Architecture Patterns
- **Layered architecture** â€” Respect layer boundaries defined in [`repomap.toml`](../../repomap.toml)
- **Deterministic artifacts** â€” Same input â†’ same output, always
- **Evidence-based claims** â€” Every claim backed by verifiable evidence
- **Virtual environment mandate** â€” ALWAYS use `.venv/bin/python -m ...`

### Testing Strategy
- **Pytest markers** â€” Use `@pytest.mark.live` for tests requiring external services
- **Update existing tests** â€” Don't create new test files unless explicitly requested
- **Quality gates** â€” All must pass via `gate quality`

### State Management
- **Artifacts in `.repomap/`** â€” Generated artifacts stored here
- **Canonical claims** â€” `repomap_claims.jsonl` tracked in git
- **Experimental claims** â€” `docs/experiments/claims-archive/` for analysis

---

## EXIT GATE: Punch Card Checkpoint

**Before calling `attempt_completion`, you MUST run the punch card checkpoint.**

> ğŸ“Œ `mint punches {task_id}` â†’ [`commands.punch_mint`](../commands.toml)
> Resolves to: `python3 .kilocode/tools/punch_engine.py mint {task_id}`

> ğŸšª `checkpoint punch-card {task_id} prep-task` â†’ [`commands.punch_checkpoint`](../commands.toml)
> Resolves to: `python3 .kilocode/tools/punch_engine.py checkpoint {task_id} prep-task`
> **receipt_required = true** â€” this is a hard gate.

**If checkpoint FAILS:** Do NOT call `attempt_completion`. Review which required punches
are missing, complete the missing steps, re-mint, and re-checkpoint.

**If checkpoint PASSES:** Proceed to `attempt_completion` with the prepared task.

---

## Example: Transforming a Vague Request

### Before (Vague)
> "Fix the memory bug"

### After Applying the Protocol

**Phase 1 â€” Problem Definition:**

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Interpretation 1: Memory leak in artifact storage causing disk space issues"
  stage=Problem Definition, tags=[interpretation, memory]

decompose task: "Interpretation 2: Claims not being garbage collected, causing RAM issues"
  stage=Problem Definition, tags=[interpretation, memory]
  assumptions_challenged=[Issue is disk-related]
```

**Phase 2 â€” Research:**

> ğŸ“Œ `retrieve codebase` â†’ [`commands.retrieve_codebase`](../commands.toml)

Used to find artifact-related code in `artifact_store.py`, `io.py`, and `write.py`.

**Phase 3 â€” Analysis:**
Generated 3 approaches: fix leak, add cleanup, implement LRU cache

**Phase 4 â€” Synthesis:**

> ğŸ“Œ `summarize thinking` â†’ [`commands.summarize_thinking`](../commands.toml)

Verified 2 interpretations, 3 approaches explored.

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Comparison: Approach 1 (fix leak) is simplest and addresses root cause. Approach 2 (cleanup) is workaround. Approach 3 (LRU) is over-engineering. Recommend Approach 1."
  stage=Synthesis, tags=[comparison]
```

**Phase 5 â€” Conclusion:**

> ğŸ“Œ `decompose task` â†’ [`commands.decompose_task`](../commands.toml)

```
decompose task: "Decision: Fix artifact storage leak in artifact_store.py. Add proper file handle cleanup. Success criteria: No open file handles after write, pytest passes, no disk space growth."
  stage=Conclusion, tags=[decision]
  axioms_used=[Fail hard, not silently]
```

> ğŸ“Œ `export session` â†’ [`commands.export_session`](../commands.toml)

File path: `.kilocode/thinking/fix-artifact-leak-{YYYY-MM-DD}.json`

---

## Success Criteria Checklist

Before beginning implementation, verify all phases are complete:

```markdown
## Pre-Implementation Checklist

### Understanding
- [ ] At least 2 interpretation branches created
- [ ] Relevant architecture and patterns reviewed
- [ ] External library APIs verified with Context7

### Planning
- [ ] At least 2 approach candidates generated
- [ ] Success criteria defined with measurable outcomes
- [ ] `summarize thinking` called to verify exploration

### Validation
- [ ] Conclusion stage reached with clear decision
- [ ] Alignment with project conventions confirmed
- [ ] Session exported for future reference

### Preservation
- [ ] User-provided code samples preserved verbatim
- [ ] No unsolicited documentation planned
- [ ] No new files unless explicitly required
```

---

## Quick Reference: Tool by Phase

| Phase | Primary Commands |
|-------|-----------------|
| 0. Sequential Thinking | `decompose task` â†’ `commands.decompose_task`, `summarize thinking` â†’ `commands.summarize_thinking`, `export session` â†’ `commands.export_session` |
| 1. Problem Definition | `decompose task` (branching), `retrieve codebase` â†’ `commands.retrieve_codebase` |
| 2. Research | `retrieve codebase`, `read_file`, `resolve library` â†’ `commands.resolve_library`, `query docs` â†’ `commands.query_docs` |
| 3. Analysis | `decompose task` (approach candidates) |
| 4. Synthesis | `summarize thinking`, `decompose task` (comparison) |
| 5. Conclusion | `decompose task` (decision), `export session` |

---

## Context7 Integration

Context7 provides up-to-date documentation for third-party libraries. **This is critical**â€”LLM training data is often stale, and library APIs change. Using Context7 prevents fighting against libraries by ensuring you use them as intended.

### When to Use Context7

**Always use Context7 when:**
- Writing new code that imports any external library
- Debugging errors that might be API misuse
- Implementing patterns from a framework
- Upgrading or changing library versions
- Unsure about correct method signatures, parameters, or return types

**Key Repomap dependencies requiring Context7 verification:**
- `tree-sitter` â€” Language parsers, query syntax, node traversal
- `pydantic` â€” Model validation, serialization patterns
- `typer` â€” CLI framework, command decorators, parameter types
- `langchain` â€” LLM orchestration (experimental / out-of-scope for repomap-core)
- `weaviate-client` â€” Vector search, collections (optional)
- `pytest` â€” Fixtures, markers, parametrization

### Context7 Workflow

> ğŸ“Œ `resolve library` â†’ [`commands.resolve_library`](../commands.toml)
> Resolves to: `mcp--context7--resolve___library___id`

> ğŸ“Œ `query docs` â†’ [`commands.query_docs`](../commands.toml)
> Resolves to: `mcp--context7--query___docs`

If context insufficient, refine query or paginate.

### Integration with Execution Pattern

Context7 calls should happen in **Phase 2 (Research)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LIBRARY-AWARE RESEARCH                                         â”‚
â”‚  â”œâ”€â”€ Identify external imports in target code                   â”‚
â”‚  â”œâ”€â”€ resolve library               â†’ commands.resolve_library   â”‚
â”‚  â”œâ”€â”€ query docs                    â†’ commands.query_docs        â”‚
â”‚  â”œâ”€â”€ decompose task (document findings)                         â”‚
â”‚  â”‚                                 â†’ commands.decompose_task    â”‚
â”‚  â””â”€â”€ THEN proceed to Analysis phase                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Anti-Patterns to Avoid

- âŒ **Guessing API signatures** from memory or training data
- âŒ **Assuming library behavior** without verification
- âŒ **Debugging for hours** when the issue is outdated API usage
- âŒ **Copy-pasting old code patterns** without checking if they're still valid
- âœ… **Verify first, code second** â€” 30 seconds of Context7 saves hours of debugging

---

## Related Workflows

- [`/start-task`](./start-task.md) â€” Meta-workflow that calls this as Phase 3
- [`/execute-task`](./execute-task.md) â€” Implementation phase (after approval)
- [`/codebase-exploration`](./codebase-exploration.md) â€” Deep dive into code structure

## Related Skills

- [`beads-local-db-ops`](../skills/beads-local-db-ops/SKILL.md) â€” Beads CLI operations
- [`repomap-codebase-retrieval`](../skills/repomap-codebase-retrieval/SKILL.md) â€” Semantic code search
- [`sequential-thinking-default`](../skills/sequential-thinking-default/SKILL.md) â€” Multi-step reasoning
- [`context7-docs-ops`](../skills/context7-docs-ops/SKILL.md) â€” Library documentation

## Philosophy: Software Fabrication

- **Determinism** â€” Same task â†’ same preparation â†’ same execution
- **Evidence-based** â€” Decisions backed by codebase analysis
- **Structure discipline** â€” commands.toml routes all the way down
- **Self-verifying** â€” Punch card checkpoint gates the exit
